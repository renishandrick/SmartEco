"""
Auto-Training Service
Automatically retrains ML models using real telemetry data from MongoDB
"""
import asyncio
import numpy as np
from datetime import datetime, timedelta
from sklearn.ensemble import IsolationForest, RandomForestRegressor
import joblib
import os
from database import get_db

class AutoTrainer:
    def __init__(self):
        self.model_dir = "ml_models_trained"
        os.makedirs(self.model_dir, exist_ok=True)
        
        self.anomaly_model_path = os.path.join(self.model_dir, "anomaly_detector.pkl")
        self.maintenance_model_path = os.path.join(self.model_dir, "maintenance_predictor.pkl")
        
        self.last_training_time = None
        self.training_stats = {
            "data_points": 0,
            "anomaly_score": 0.0,
            "maintenance_score": 0.0,
            "last_trained": None
        }
    
    async def fetch_training_data(self, hours=24, min_samples=100):
        """Fetch historical telemetry data from MongoDB"""
        db = get_db()
        
        if not db.connected:
            print("‚ö†Ô∏è  MongoDB not connected. Cannot fetch training data.")
            return None
        
        try:
            # Get telemetry history
            data = db.get_telemetry_history(hours=hours, limit=2000)
            
            if len(data) < min_samples:
                print(f"‚ö†Ô∏è  Not enough data for training. Got {len(data)}, need {min_samples}")
                return None
            
            # Extract features: [energy, water]
            X = np.array([[d['energy_kwh'], d['water_lpm']] for d in data])
            
            # Create labels for maintenance (synthetic but realistic)
            # Health degrades with high sustained usage
            energy_norm = (X[:, 0] - X[:, 0].min()) / (X[:, 0].max() - X[:, 0].min() + 1e-6)
            water_norm = (X[:, 1] - X[:, 1].min()) / (X[:, 1].max() - X[:, 1].min() + 1e-6)
            
            stress = energy_norm * 0.6 + water_norm * 0.4
            y_health = 100 - (stress * 20) - np.random.normal(0, 3, len(stress))
            y_health = np.clip(y_health, 60, 100)
            
            print(f"‚úÖ Fetched {len(data)} data points for training")
            return X, y_health
        
        except Exception as e:
            print(f"‚ùå Error fetching training data: {e}")
            return None
    
    async def train_models(self):
        """Train both ML models on real data"""
        print("\nüß† Starting Auto-Training Pipeline...")
        
        # Fetch data
        result = await self.fetch_training_data(hours=24, min_samples=50)
        
        if result is None:
            print("‚ö†Ô∏è  Skipping training - insufficient data")
            return False
        
        X, y_health = result
        n_samples = len(X)
        
        # 1. Train Anomaly Detector
        print("   Training Anomaly Detector...")
        anomaly_model = IsolationForest(
            contamination=0.05,
            random_state=42,
            n_estimators=100
        )
        anomaly_model.fit(X)
        
        # Calculate anomaly score (% of data classified as normal)
        predictions = anomaly_model.predict(X)
        anomaly_score = (predictions == 1).sum() / len(predictions) * 100
        
        # 2. Train Maintenance Predictor
        print("   Training Maintenance Predictor...")
        maintenance_model = RandomForestRegressor(
            n_estimators=100,
            random_state=42,
            max_depth=10
        )
        maintenance_model.fit(X, y_health)
        
        # Calculate R¬≤ score
        maintenance_score = maintenance_model.score(X, y_health) * 100
        
        # 3. Save Models
        print("   Saving trained models...")
        joblib.dump(anomaly_model, self.anomaly_model_path)
        joblib.dump(maintenance_model, self.maintenance_model_path)
        
        # 4. Update Stats
        self.last_training_time = datetime.now()
        self.training_stats = {
            "data_points": n_samples,
            "anomaly_score": round(anomaly_score, 1),
            "maintenance_score": round(maintenance_score, 1),
            "last_trained": self.last_training_time.isoformat()
        }
        
        print(f"‚úÖ Training Complete!")
        print(f"   - Data Points: {n_samples}")
        print(f"   - Anomaly Detection Accuracy: {anomaly_score:.1f}%")
        print(f"   - Maintenance Prediction R¬≤: {maintenance_score:.1f}%")
        
        return True
    
    def get_stats(self):
        """Return training statistics for frontend"""
        return self.training_stats
    
    def models_exist(self):
        """Check if trained models exist on disk"""
        return (os.path.exists(self.anomaly_model_path) and 
                os.path.exists(self.maintenance_model_path))

# Global instance
AUTO_TRAINER = AutoTrainer()

async def auto_training_loop():
    """Background task that trains models periodically"""
    while True:
        try:
            # Wait 30 minutes between training runs
            await asyncio.sleep(1800)  # 30 minutes
            
            print("\n‚è∞ Auto-Training Schedule Triggered")
            await AUTO_TRAINER.train_models()
            
        except Exception as e:
            print(f"‚ùå Auto-training error: {e}")
            await asyncio.sleep(60)  # Retry in 1 minute on error
